{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7354e39c-9a36-49ec-91be-b8155d443ebe",
   "metadata": {},
   "source": [
    "## Notebook #2: Initial Models and Null Model\n",
    "\n",
    "In this notebook, I will form my first simple models including a basic linear regression based on the initial relationships I found in my cleaning process. As I explained in the first notebook, I did not realize I shouldn't have dropped those high NA columns until later, so you will see that they have been dropped again in this notebook. I will also evaluate the null model to get a baseline for metrics moving forward.\n",
    "\n",
    "My first model is a multiple linear regression with just 5 features and no pre-processing. This will allow me to examine relationships on a simplified level.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "aee31b34-1888-4b28-be18-9d9ce6928b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding all used libraries to the top of every notebook\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LassoCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d630f65e-2148-4a01-a578-8745a0975376",
   "metadata": {},
   "source": [
    "**BASIC LINEAR MODEL:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "id": "cd297cf3-3cf6-4363-8bbd-bd708d776dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_start.drop(columns=['saleprice'])  #using the df_start dataset I created in notebook #1\n",
    "y = df_start['saleprice']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "id": "8e828b98-2a99-4257-8922-1aa0296b72d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_id = df_house['id']\n",
    "val_id = df_house['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "id": "63ba0886-d397-4461-95c8-31bb974d409d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1536, 5)"
      ]
     },
     "execution_count": 592,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "id": "3161d1ef-041c-44f8-bb4d-162af04fd378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 593,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "id": "aaf890fc-9d67-40cd-840b-42f96d637644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7840044598338779, 0.8014371676336479)"
      ]
     },
     "execution_count": 594,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X_train, y_train), lr.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc8543a-8798-48db-8bbc-3d5a7a3bfb73",
   "metadata": {},
   "source": [
    "As we can see here, the initial model didn't do horribly actually! But it did not perform as well as it could. 78-80% of the variation in our data can be explained by this first model; however, that $R^2$ can be improved. Let's look at some more metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "id": "1edc561e-0b65-41b3-ac36-5c3879e19b37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('year_remod/add', 398.02332980492326),\n",
       " ('gr_liv_area', 64.52784582745593),\n",
       " ('totrms_abvgrd', -2815.5170684130785),\n",
       " ('overall_qual', 23712.718046978935),\n",
       " ('garage_area', 71.17705835488985)]"
      ]
     },
     "execution_count": 595,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(X_train.columns, lr.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "id": "8ec89501-06c8-45fb-803a-9b1ac74f10cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.788632862255539"
      ]
     },
     "execution_count": 596,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(lr, X, y, cv = 10).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcacbe2-250c-468c-a7fd-2a6dcf406586",
   "metadata": {},
   "source": [
    "What is encouraging about this model is that the $R^2$ for all evaluations (X_train, X_val, and cross val) are around the same number. This shows that there is a good bias-variance trade off in our model and data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "id": "8ca3205d-1e78-4ad6-8b03-c713bd7c53fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_preds = lr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "id": "b5a544df-b056-4b82-9afd-5d2ece886923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1354789141.6102898"
      ]
     },
     "execution_count": 599,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_train, y_train_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "id": "f9b0a724-a3ed-456b-9af0-839bcaef46ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_preds = lr.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "id": "56677abc-a945-45d6-8523-6b5e97705f8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1255336973.9312356"
      ]
     },
     "execution_count": 601,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_val, y_val_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8509d4-3ea4-48a8-a8f3-ac748d4c3f2f",
   "metadata": {},
   "source": [
    "Whew! These are some very high mean squared error scores (should be as close to 0 as possible). To have a better understanding of these numbers, a look at the null model is necessary. \n",
    "\n",
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ca14b3-d4cf-4601-b051-0868505e1453",
   "metadata": {},
   "source": [
    "**NULL MODEL:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "7bdfce59-20b5-4bcf-9ed6-8a487c8d7300",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_baseline_preds = np.full_like(y, y.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "40e431e4-ebcf-4dcb-9d5a-7ab1f1274a25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([181643, 181643, 181643, ..., 181643, 181643, 181643])"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_baseline_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "id": "240d7838-c0f4-4d20-8d34-33c73605903b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6284773122.026842"
      ]
     },
     "execution_count": 587,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y, y_baseline_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ee7ded-8959-4bfa-b3db-0f9b1f31456e",
   "metadata": {},
   "source": [
    "From calculating the mean squared error of the null model, we can see that even the initial linear regression model would be a better fit for the data than just predicting the mean for each data point (what the null model is doing). As I continue to develop my models, I will refer back to this null model mean squared error score to ensure I am not losing track of a well fitting model.\n",
    "\n",
    "--- \n",
    "\n",
    "Next, I will put my initial linear regression model into a Lasso CV regularization and add in all numeric variables. In the end, I want to be able to isolate relevant features from the data. As I build my model, I will continue to add in and take out features to see what best fits the data. I am choosing to start with Lasso CV because it would help me truly isolate those best variables due to the absolute zero penalty within the function. Further, I saw some multicolinearity between some features, and Lasso CV can help wrangle that to something that is workable by decreasing the variance. I am choosing the CV version over the plain Lasso regularization because I want to add the extra testing of cross validation within my model. I will use these scores continually throughout this project to see how my model is doing to explain the variation in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efcd14b-796e-4077-a53b-2a58e55f0b03",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "For the first Lasso CV model I made, I only wanted the numeric columns from the data. Therefore, I created a new dataset called df_nums containing only those features, as seen below. This allowed me to isolate only the columns I wanted to test. This dataset will continue to be used throughout the modeling process. The df_start dataset will no longer be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "id": "2c6530df-8f78-4b13-8fe2-acf9713c9867",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ms_subclass</th>\n",
       "      <th>lot_frontage</th>\n",
       "      <th>lot_area</th>\n",
       "      <th>overall_qual</th>\n",
       "      <th>overall_cond</th>\n",
       "      <th>year_built</th>\n",
       "      <th>year_remod/add</th>\n",
       "      <th>mas_vnr_area</th>\n",
       "      <th>bsmtfin_sf_1</th>\n",
       "      <th>bsmtfin_sf_2</th>\n",
       "      <th>bsmt_unf_sf</th>\n",
       "      <th>total_bsmt_sf</th>\n",
       "      <th>1st_flr_sf</th>\n",
       "      <th>2nd_flr_sf</th>\n",
       "      <th>low_qual_fin_sf</th>\n",
       "      <th>gr_liv_area</th>\n",
       "      <th>bsmt_full_bath</th>\n",
       "      <th>bsmt_half_bath</th>\n",
       "      <th>full_bath</th>\n",
       "      <th>half_bath</th>\n",
       "      <th>bedroom_abvgr</th>\n",
       "      <th>kitchen_abvgr</th>\n",
       "      <th>totrms_abvgrd</th>\n",
       "      <th>fireplaces</th>\n",
       "      <th>garage_yr_blt</th>\n",
       "      <th>garage_cars</th>\n",
       "      <th>garage_area</th>\n",
       "      <th>wood_deck_sf</th>\n",
       "      <th>open_porch_sf</th>\n",
       "      <th>enclosed_porch</th>\n",
       "      <th>3ssn_porch</th>\n",
       "      <th>screen_porch</th>\n",
       "      <th>pool_area</th>\n",
       "      <th>misc_val</th>\n",
       "      <th>mo_sold</th>\n",
       "      <th>yr_sold</th>\n",
       "      <th>saleprice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>109</td>\n",
       "      <td>60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13517</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>2005</td>\n",
       "      <td>289.0</td>\n",
       "      <td>533.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>725.0</td>\n",
       "      <td>725</td>\n",
       "      <td>754</td>\n",
       "      <td>0</td>\n",
       "      <td>1479</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>475.0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>130500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>544</td>\n",
       "      <td>60</td>\n",
       "      <td>43.0</td>\n",
       "      <td>11492</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1996</td>\n",
       "      <td>1997</td>\n",
       "      <td>132.0</td>\n",
       "      <td>637.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>913.0</td>\n",
       "      <td>913</td>\n",
       "      <td>1209</td>\n",
       "      <td>0</td>\n",
       "      <td>2122</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>559.0</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2009</td>\n",
       "      <td>220000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153</td>\n",
       "      <td>20</td>\n",
       "      <td>68.0</td>\n",
       "      <td>7922</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1953</td>\n",
       "      <td>2007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>731.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>1057.0</td>\n",
       "      <td>1057</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1057</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1953.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>109000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  ms_subclass  lot_frontage  lot_area  overall_qual  overall_cond  \\\n",
       "0  109           60           NaN     13517             6             8   \n",
       "1  544           60          43.0     11492             7             5   \n",
       "2  153           20          68.0      7922             5             7   \n",
       "\n",
       "   year_built  year_remod/add  mas_vnr_area  bsmtfin_sf_1  bsmtfin_sf_2  \\\n",
       "0        1976            2005         289.0         533.0           0.0   \n",
       "1        1996            1997         132.0         637.0           0.0   \n",
       "2        1953            2007           0.0         731.0           0.0   \n",
       "\n",
       "   bsmt_unf_sf  total_bsmt_sf  1st_flr_sf  2nd_flr_sf  low_qual_fin_sf  \\\n",
       "0        192.0          725.0         725         754                0   \n",
       "1        276.0          913.0         913        1209                0   \n",
       "2        326.0         1057.0        1057           0                0   \n",
       "\n",
       "   gr_liv_area  bsmt_full_bath  bsmt_half_bath  full_bath  half_bath  \\\n",
       "0         1479             0.0             0.0          2          1   \n",
       "1         2122             1.0             0.0          2          1   \n",
       "2         1057             1.0             0.0          1          0   \n",
       "\n",
       "   bedroom_abvgr  kitchen_abvgr  totrms_abvgrd  fireplaces  garage_yr_blt  \\\n",
       "0              3              1              6           0         1976.0   \n",
       "1              4              1              8           1         1997.0   \n",
       "2              3              1              5           0         1953.0   \n",
       "\n",
       "   garage_cars  garage_area  wood_deck_sf  open_porch_sf  enclosed_porch  \\\n",
       "0          2.0        475.0             0             44               0   \n",
       "1          2.0        559.0             0             74               0   \n",
       "2          1.0        246.0             0             52               0   \n",
       "\n",
       "   3ssn_porch  screen_porch  pool_area  misc_val  mo_sold  yr_sold  saleprice  \n",
       "0           0             0          0         0        3     2010     130500  \n",
       "1           0             0          0         0        4     2009     220000  \n",
       "2           0             0          0         0        1     2010     109000  "
      ]
     },
     "execution_count": 573,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nums = df_house.select_dtypes(include=[np.number])\n",
    "df_nums.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "id": "7f6b7e78-1788-4ad0-9a09-04b67d90cc12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T15:17:32.466529Z",
     "start_time": "2021-05-04T15:17:32.446642Z"
    }
   },
   "outputs": [],
   "source": [
    "house_features = [col for col in df_nums.columns if col != 'saleprice' and 'id']  # list comp instead of dropping the columns by hand\n",
    "\n",
    "X = df_nums[house_features].drop(columns='id')\n",
    "y = df_nums['saleprice']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c81f67-3759-4447-9fb3-5924c556cf20",
   "metadata": {},
   "source": [
    "As I worked through the first few models, I made many mistakes. I discussed one of those in my first notebook (dropping columns from misunderstanding the data description). Another mistake I made was imputing the missing values with the mean instead of 0 constant. I filled the values with the mean because, again, I did not read or understand the data description fully before beginning my modeling process. I have definitely learned that lesson! However, I wanted to show my honest process, so I am keeping my initial mistakes in here. Later, I will fix this to replace the missing values with 0 as the NA in the data description does not mean those data points are missing - just a 0 in the category for the variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "id": "af9c66e0-4ea4-48bf-bf8a-70d9b4c4955d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "si = SimpleImputer(strategy = 'mean')  #replacing missing values\n",
    "\n",
    "X_train_fill = si.fit_transform(X_train)\n",
    "X_val_fill = si.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "id": "b6d637b1-810b-42d3-9b6b-2fb0f2b08502",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_fill = pd.DataFrame(X_train_fill, columns = si.feature_names_in_)\n",
    "X_val_fill = pd.DataFrame(X_val_fill, columns = si.feature_names_in_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "id": "b748d20d-6c50-435a-8042-df0408b0490d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ss = StandardScaler()  # scaling the data before regularization\n",
    "X_train_sc = ss.fit_transform(X_train_fill)\n",
    "X_val_sc = ss.transform(X_val_fill)\n",
    "\n",
    "X_train_sc = pd.DataFrame(X_train_sc, columns = ss.get_feature_names_out())\n",
    "X_val_sc = pd.DataFrame(X_val_sc, columns = ss.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "id": "cee52341-5f2f-479d-a35a-6257ca2b05ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T15:32:11.760496Z",
     "start_time": "2021-05-04T15:32:11.419722Z"
    },
    "code_folding": [],
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best alpha: 274.5271935073856\n",
      "score: 0.8712124957532725\n"
     ]
    }
   ],
   "source": [
    "lasso_cv = LassoCV(cv = 10).fit(X_train_sc, y_train)  # using 10 cross val k-folds for robust validation process\n",
    "\n",
    "print('best alpha:', lasso_cv.alpha_)\n",
    "print('score:', lasso_cv.score(X_train_sc, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "id": "704438b8-2ea3-4220-b99f-464cfc8dfe93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T15:34:52.805081Z",
     "start_time": "2021-05-04T15:34:52.776233Z"
    }
   },
   "outputs": [],
   "source": [
    "new_lasso = Lasso(alpha = lasso_cv.alpha_)\n",
    "new_lasso.fit(X_train_sc, y_train)\n",
    "\n",
    "final_columns = [col for col, coef in zip(X_train_sc.columns, new_lasso.coef_) if coef]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "48f40f2f-d487-4b55-8d24-21a712935a64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T15:36:01.852275Z",
     "start_time": "2021-05-04T15:36:01.489169Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9029829428704517"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "cross_val_score(lr, X_train_sc[final_columns], y_train, cv=10, n_jobs = -1).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e17880-1379-4259-944e-f1610bc762e0",
   "metadata": {},
   "source": [
    "Here, I ran the Lasso CV to get the best alpha. Then, I ran that alpha back through a regular Lasso model along with the best features from that model to see what would happen. It turned out that my model performed better when it just went through the Lasso CV fit rather than the second round of regularization. This is the first and final time I tried this. As you can see, my $R^2$ scores, again, are not terrible. I want to keep improving though. This is the first model I submitted to Kaggle (final Kaggle submission on notebook #5). It scored around 31,000. \n",
    "\n",
    "---\n",
    "\n",
    "In an attempt to simply try many different things within my model, I next tried adding or taking away PolynomialFeatures, RFE Feature Selection, RidgeCV, and ElasticNetCV. Polynomial Features ended up working for my Kaggle model, but unfortunately, a model with almost 2000 more features than it has data points is not something that I would send to production. The issue with that is the high variance of having so many added features, and not enough data points. Regularization and RFE Feature Selection should bring this down, but it ultimately led to me having a way overfit model to the train set, and very underpreforming on the test set. The model built below has some of those things I added and took away in commented form. Most other things are the same, but you can see where I would be able to add a code block back in as a test.\n",
    "\n",
    "Along with adding and taking away transformers, I also messed around with the features I would add vs take away. At one point, I added all features in the data set, did PolynomialFeatures, and ended up with over 11,000 features and about 1,500 data points. Obviously, that was a very badly performing model. But, in my draw to learn, I loved trying out anything I could think of. I submitted variations of this model to Kaggle before landing on the final one in notebook #5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1b6a0197-6597-42e0-8a19-447f65af2f0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T15:17:32.466529Z",
     "start_time": "2021-05-04T15:17:32.446642Z"
    }
   },
   "outputs": [],
   "source": [
    "X = df_combined.drop(columns=['id', 'saleprice'])\n",
    "y = np.log(df_combined['saleprice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b8655136-0de4-4fcd-a530-e97d9794e8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a9d7afa2-4270-49b7-b902-9b0d8edf8cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dfc64243-9da1-45c3-b882-a65551d8c744",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_transformer\n",
    "ohe = OneHotEncoder(handle_unknown='ignore')\n",
    "smart_encoder = make_column_transformer((ohe,\n",
    "                                        ['neighborhood', 'house_style', 'exter_qual', 'kitchen_qual']),\n",
    "                                        remainder='passthrough',\n",
    "                                        verbose_feature_names_out=False)\n",
    "\n",
    "X_train_enc = smart_encoder.fit_transform(X_train)\n",
    "X_val_enc = smart_encoder.transform(X_val)\n",
    "\n",
    "X_train_enc = pd.DataFrame(X_train_enc, columns = smart_encoder.get_feature_names_out())\n",
    "X_val_enc = pd.DataFrame(X_val_enc, columns = smart_encoder.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a35fc28b-2bb0-4281-997d-5cf461ae7cd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "si = SimpleImputer(strategy = 'mean')  # at this point, I still had not realized my mistake with the mean vs constant 0\n",
    "\n",
    "\n",
    "X_train_fill = si.fit_transform(X_train_enc)\n",
    "X_val_fill = si.transform(X_val_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "57dfa882-346d-4b93-bbdb-81fa22f629ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_fill = pd.DataFrame(X_train_fill, columns = si.feature_names_in_)\n",
    "X_val_fill = pd.DataFrame(X_val_fill, columns = si.feature_names_in_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "38dc6fca-9816-48fa-87d6-7cbc630985b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "X_train_sc = ss.fit_transform(X_train_fill)\n",
    "X_val_sc = ss.transform(X_val_fill)\n",
    "\n",
    "X_train_sc = pd.DataFrame(X_train_sc, columns = ss.get_feature_names_out())\n",
    "X_val_sc = pd.DataFrame(X_val_sc, columns = ss.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3b2c1283-15f0-4afc-ab03-ff82c80f7ba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1536, 80)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "958eae2e-135d-4aa6-b289-036fdd14568d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import PolynomialFeatures\n",
    "# poly = PolynomialFeatures(include_bias=False)\n",
    "# X_train_p = poly.fit_transform(X_train_sc)\n",
    "# X_val_p = poly.transform(X_val_sc)\n",
    "\n",
    "# X_train_p = pd.DataFrame(X_train_p, columns = poly.get_feature_names_out())\n",
    "# X_val_p = pd.DataFrame(X_val_p, columns = poly.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "37b4727f-bad5-4bcc-93aa-a0f99b37e732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_selection import RFE\n",
    "# rfe = RFE(estimator=LinearRegression())\n",
    "# X_train_half = rfe.fit_transform(X_train_p, y_train)\n",
    "# X_val_half = rfe.transform(X_val_p)\n",
    "# X_train_half = pd.DataFrame(X_train_half, columns = rfe.get_feature_names_out())\n",
    "# X_val_half = pd.DataFrame(X_val_half, columns = rfe.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f651e4ad-7b45-4afc-b93a-b5762e5c4dc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1536, 80)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "49bafb2d-bb29-4957-a6ae-f3025098479e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best alpha: 10.0\n",
      "score: 0.9190596946095148\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "rg_cv = RidgeCV(cv= 10).fit(X_train_sc, y_train)\n",
    "\n",
    "print('best alpha:', rg_cv.alpha_)\n",
    "print('score:', rg_cv.score(X_train_sc, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "12a23306-b154-4593-8bba-7c54edacb7db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T15:32:11.760496Z",
     "start_time": "2021-05-04T15:32:11.419722Z"
    },
    "code_folding": [],
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import ElasticNetCV\n",
    "\n",
    "# elastic_cv = ElasticNetCV(cv= 10, n_jobs=-1).fit(X_train_sc, y_train)\n",
    "\n",
    "# print('best alpha:', elastic_cv.alpha_)\n",
    "# print('score:', elastic_cv.score(X_train_sc, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1636473d-b3c3-44df-8dfe-86f05f039635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8930552952169875"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rg_cv.score(X_val_sc, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605c0673-c6c5-44df-830e-ed28a726956c",
   "metadata": {},
   "source": [
    "The last model I tried as a part of this exploration finally introduced the steps that led to my best model. I remembered that, when I did my initial analysis, I graphed a histogram of sale price. Initially, it looked a little skewed, so I applied a log transformation, and that made the distribution more normal. I found a way to add this to my model using TransformedTargetRegressor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2437afe8-4ea6-44bb-a18e-171e3d91093b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T15:17:32.466529Z",
     "start_time": "2021-05-04T15:17:32.446642Z"
    }
   },
   "outputs": [],
   "source": [
    "X = df_combined.drop(columns=['id', 'saleprice'])\n",
    "y = df_combined['saleprice']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "396a5727-05b5-48e8-869c-3f3ef6a6941b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(handle_unknown='ignore')\n",
    "smart_encoder = make_column_transformer((ohe,\n",
    "                                        ['neighborhood', 'house_style', 'exter_qual', 'kitchen_qual']),\n",
    "                                        remainder='passthrough',\n",
    "                                        verbose_feature_names_out=False)\n",
    "\n",
    "X_train_enc = smart_encoder.fit_transform(X_train)\n",
    "X_val_enc = smart_encoder.transform(X_val)\n",
    "\n",
    "X_train_enc = pd.DataFrame(X_train_enc, columns = smart_encoder.get_feature_names_out())\n",
    "X_val_enc = pd.DataFrame(X_val_enc, columns = smart_encoder.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9aef2b26-46a2-4d67-938c-88e0ef1c6526",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "si = SimpleImputer(strategy = 'mean')\n",
    "# si = SimpleImputer(strategy = 'constant', fill_value=0)\n",
    "\n",
    "X_train_fill = si.fit_transform(X_train_enc)\n",
    "X_val_fill = si.transform(X_val_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7779c0f1-aef0-4783-b526-694876f3464a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_fill = pd.DataFrame(X_train_fill, columns = si.feature_names_in_)\n",
    "X_val_fill = pd.DataFrame(X_val_fill, columns = si.feature_names_in_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "18c441fb-b855-4dcf-a335-f0b4e90919bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "X_train_sc = ss.fit_transform(X_train_fill)\n",
    "X_val_sc = ss.transform(X_val_fill)\n",
    "\n",
    "X_train_sc = pd.DataFrame(X_train_sc, columns = ss.get_feature_names_out())\n",
    "X_val_sc = pd.DataFrame(X_val_sc, columns = ss.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ef7bba21-fe5f-4b92-935f-10f88ec36138",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-04T15:32:11.760496Z",
     "start_time": "2021-05-04T15:32:11.419722Z"
    },
    "code_folding": [],
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best alpha: 294.3665111484536\n",
      "score: 0.9147164487058445\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "lasso_cv = LassoCV(cv = 10).fit(X_train_sc, y_train)\n",
    "\n",
    "print('best alpha:', lasso_cv.alpha_)\n",
    "print('score:', lasso_cv.score(X_train_sc, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "886bef76-afdf-4ef6-a854-93005927feb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9209348090028185"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_cv.score(X_val_sc, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4b6cd058-8132-4834-9c35-ff23f0667b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import TransformedTargetRegressor\n",
    "tt = TransformedTargetRegressor(regressor = lasso_cv, func = np.log, inverse_func = np.exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "24cae5e5-fafc-4659-86a0-1b2a03231e50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformedTargetRegressor(func=<ufunc 'log'>, inverse_func=<ufunc 'exp'>,\n",
       "                           regressor=LassoCV(cv=10))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt.fit(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f2eceaf6-4063-442b-a171-3953566e642e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9348260075279748"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt.score(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bfb568cf-4398-46c9-b99e-cdc770d0876e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9359349820822778"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt.score(X_val_sc, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d93e3896-3ca5-4c21-b704-db101bf567e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_coefs = lasso_cv.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2c1eddc0-cbb5-41b6-bb16-8342f5faec30",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neighborhood_Blmngtn',\n",
       " 'neighborhood_BrkSide',\n",
       " 'neighborhood_ClearCr',\n",
       " 'neighborhood_Crawfor',\n",
       " 'neighborhood_GrnHill',\n",
       " 'neighborhood_NPkVill',\n",
       " 'neighborhood_NoRidge',\n",
       " 'neighborhood_NridgHt',\n",
       " 'neighborhood_SWISU',\n",
       " 'neighborhood_Somerst',\n",
       " 'neighborhood_StoneBr',\n",
       " 'neighborhood_Timber',\n",
       " 'house_style_1.5Unf',\n",
       " 'house_style_2.5Fin',\n",
       " 'house_style_2.5Unf',\n",
       " 'house_style_SFoyer',\n",
       " 'house_style_SLvl',\n",
       " 'exter_qual_Ex',\n",
       " 'kitchen_qual_Ex',\n",
       " 'lot_frontage',\n",
       " 'lot_area',\n",
       " 'overall_qual',\n",
       " 'overall_cond',\n",
       " 'year_built',\n",
       " 'year_remod/add',\n",
       " 'mas_vnr_area',\n",
       " 'bsmtfin_sf_1',\n",
       " 'bsmtfin_sf_2',\n",
       " 'total_bsmt_sf',\n",
       " '2nd_flr_sf',\n",
       " 'gr_liv_area',\n",
       " 'bsmt_full_bath',\n",
       " 'full_bath',\n",
       " 'half_bath',\n",
       " 'totrms_abvgrd',\n",
       " 'fireplaces',\n",
       " 'garage_yr_blt',\n",
       " 'garage_cars',\n",
       " 'garage_area',\n",
       " 'wood_deck_sf',\n",
       " 'open_porch_sf',\n",
       " 'enclosed_porch',\n",
       " '3ssn_porch',\n",
       " 'screen_porch']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[col for col,coef in list(zip(X_train_sc.columns, col_coefs)) if coef > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "35dffcfe-d890-466e-8261-44d504f1fecd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('neighborhood_Blmngtn', 429.89320651687893),\n",
       " ('neighborhood_Blueste', 0.0),\n",
       " ('neighborhood_BrDale', -0.0),\n",
       " ('neighborhood_BrkSide', 1253.6533894337874),\n",
       " ('neighborhood_ClearCr', 510.396871948398),\n",
       " ('neighborhood_CollgCr', 0.0),\n",
       " ('neighborhood_Crawfor', 3220.6544520134767),\n",
       " ('neighborhood_Edwards', -0.0),\n",
       " ('neighborhood_Gilbert', -150.9269357624419),\n",
       " ('neighborhood_Greens', 0.0),\n",
       " ('neighborhood_GrnHill', 2691.865215522986),\n",
       " ('neighborhood_IDOTRR', 0.0),\n",
       " ('neighborhood_Landmrk', 0.0),\n",
       " ('neighborhood_MeadowV', -0.0),\n",
       " ('neighborhood_Mitchel', -16.25815213341542),\n",
       " ('neighborhood_NAmes', -938.1657802376317),\n",
       " ('neighborhood_NPkVill', 123.80377586837243),\n",
       " ('neighborhood_NWAmes', -2478.279666898217),\n",
       " ('neighborhood_NoRidge', 4360.1458793303655),\n",
       " ('neighborhood_NridgHt', 6116.405220064707),\n",
       " ('neighborhood_OldTown', -175.56948564336201),\n",
       " ('neighborhood_SWISU', 415.32312320180387),\n",
       " ('neighborhood_Sawyer', -441.9637122737224),\n",
       " ('neighborhood_SawyerW', -928.489816488109),\n",
       " ('neighborhood_Somerst', 2632.398485207239),\n",
       " ('neighborhood_StoneBr', 6333.8173499707345),\n",
       " ('neighborhood_Timber', 516.9795738388262),\n",
       " ('neighborhood_Veenker', -176.68340878688795),\n",
       " ('house_style_1.5Fin', -0.0),\n",
       " ('house_style_1.5Unf', 170.54668916215311),\n",
       " ('house_style_1Story', -0.0),\n",
       " ('house_style_2.5Fin', 720.1176693105066),\n",
       " ('house_style_2.5Unf', 805.8758641503197),\n",
       " ('house_style_2Story', 0.0),\n",
       " ('house_style_SFoyer', 151.5272174569821),\n",
       " ('house_style_SLvl', 1151.6235841914165),\n",
       " ('exter_qual_Ex', 7656.773946759217),\n",
       " ('exter_qual_Fa', -284.21845557123527),\n",
       " ('exter_qual_Gd', 0.0),\n",
       " ('exter_qual_TA', -2595.0644070271564),\n",
       " ('kitchen_qual_Ex', 7662.074391744147),\n",
       " ('kitchen_qual_Fa', -0.0),\n",
       " ('kitchen_qual_Gd', 0.0),\n",
       " ('kitchen_qual_TA', -1244.7233916548012),\n",
       " ('ms_subclass', -5616.750040654802),\n",
       " ('lot_frontage', 1433.3498335818779),\n",
       " ('lot_area', 5239.815503248864),\n",
       " ('overall_qual', 13190.856692119178),\n",
       " ('overall_cond', 5361.059385653944),\n",
       " ('year_built', 10801.387720445344),\n",
       " ('year_remod/add', 2310.767028534994),\n",
       " ('mas_vnr_area', 2182.60835345922),\n",
       " ('bsmtfin_sf_1', 9024.273954067932),\n",
       " ('bsmtfin_sf_2', 1237.2370742378616),\n",
       " ('bsmt_unf_sf', -0.0),\n",
       " ('total_bsmt_sf', 7362.440786214679),\n",
       " ('1st_flr_sf', 0.0),\n",
       " ('2nd_flr_sf', 1148.2296922969522),\n",
       " ('low_qual_fin_sf', -1047.8102977936765),\n",
       " ('gr_liv_area', 23932.401918914984),\n",
       " ('bsmt_full_bath', 1120.9183807796508),\n",
       " ('bsmt_half_bath', 0.0),\n",
       " ('full_bath', 761.5344332041269),\n",
       " ('half_bath', 419.061507970877),\n",
       " ('bedroom_abvgr', -3462.72606643087),\n",
       " ('kitchen_abvgr', -1193.7495405135048),\n",
       " ('totrms_abvgrd', 2114.7666647594056),\n",
       " ('fireplaces', 1917.2844729898973),\n",
       " ('garage_yr_blt', 2035.6234188588785),\n",
       " ('garage_cars', 2178.6117024526093),\n",
       " ('garage_area', 1784.2325373602541),\n",
       " ('wood_deck_sf', 1844.1129847444183),\n",
       " ('open_porch_sf', 318.7044491108777),\n",
       " ('enclosed_porch', 76.02964396276882),\n",
       " ('3ssn_porch', 91.98566188374032),\n",
       " ('screen_porch', 3296.328895559139),\n",
       " ('pool_area', -62.32389161370459),\n",
       " ('misc_val', 0.0),\n",
       " ('mo_sold', -0.0),\n",
       " ('yr_sold', -643.4559107975621)]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(X_train_sc.columns, col_coefs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "dc16f644-ac22-4eb9-9a58-3a67d03c3fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_preds = tt.predict(X_train_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "3e88564b-9d30-4a71-963e-f93f7ce590e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "408790928.037594"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y_train, y_train_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "9f5c8153-84d5-48e8-932f-04a3608361fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "405026382.67821234"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_preds = tt.predict(X_val_sc)\n",
    "mean_squared_error(y_val, y_val_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c3b280-e799-40d6-9579-1438177fabe6",
   "metadata": {},
   "source": [
    "In this notebook, I explored many different model styles and transformers to find what worked. I ultimately learned that Ridge and ElasticNet did not do enough for my model, yet Lasso CV seemed to work really well. I assume this is because my model has many features. Additionally, I eventually learned that I needed to change my imputer to use the constant 0 instead of the mean, and that I needed to not drop those initial columns just because they had a lot of NA values. Both of these things came with spending time in the data and learning how to set up initial modeling inputs. The best MSE score I got from these temporary models was in the 408,000,000 (408 million) range, which is far better than the null model MSE of around 6,200,000,000 (6.2 billion). \n",
    "\n",
    "---\n",
    "\n",
    "In the next notebook, I will present my final model that has worked the best for me. It is able to explain my problem statement well and provide the insights I was hoping to explore. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
